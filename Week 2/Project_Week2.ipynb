{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling football stadium attendance using a GBM algorithm\n",
    "The aim of this script is to generate an artificial data set to perform a GBM algorithm and deal with overfitting.\n",
    "The script is slightly long, specially the data generation part, so do not hesitate to go fast through it. Thanks for you attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>1 min 17 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Europe/Paris</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.24.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>9 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_a_nogue_sanchez_1p1ln9</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.524 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.1 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O cluster uptime:         1 min 17 secs\n",
       "H2O cluster timezone:       Europe/Paris\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.24.0.1\n",
       "H2O cluster version age:    9 days\n",
       "H2O cluster name:           H2O_from_python_a_nogue_sanchez_1p1ln9\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.524 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.7.1 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a random data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "sampleSize = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating stadium sizes (rounded at the closest hundred)\n",
    "stadiumSize = []\n",
    "for i in range (sampleSize):\n",
    "    size = round(np.random.normal(loc = 50000, scale = 12000), -2)\n",
    "    if(size < 10000):\n",
    "        size = 10000\n",
    "    stadiumSize.append(size)\n",
    "#print(stadiumSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating players' total value (rounded at the closest thousand)\n",
    "playersValue = []\n",
    "for i in range (sampleSize):\n",
    "    # Hypothesis: players' value proportional to the stadium size + some randomness\n",
    "    playersValue.append(round(stadiumSize[i] * 20 + random.randrange(200000, 500000, 1), -3))\n",
    "#print(playersValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating players' average age\n",
    "playersAge = []\n",
    "for i in range (sampleSize):\n",
    "    # Hypothesis: age is completely random\n",
    "    playersAge.append(round(np.random.normal(27, 2), 2))\n",
    "#print(playersAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating teams' winning average\n",
    "victory = []\n",
    "for i in range (sampleSize):\n",
    "    # Hypothesis: winning 80% influenced by team's value + 20% of randomness\n",
    "    percentage = round(playersValue[i]/np.max(playersValue)*80 + np.random.normal(loc=0.5, scale=0.1)*20)\n",
    "    if(percentage < 0):\n",
    "        percentage = 0\n",
    "    elif(percentage > 100):\n",
    "        percentage = 100\n",
    "    victory.append(percentage)\n",
    "#print(victory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the output variable: average number of fans going to the stadium during the season\n",
    "attendance = []\n",
    "for i in range (sampleSize):\n",
    "    # Hypothesis 1: attendance = stadium size * 0.8 +- some randomness\n",
    "    v = round(np.random.normal(loc=stadiumSize[i]*0.6, scale = stadiumSize[i]*0.1), -2)\n",
    "    # Hypothesis 2: the higher the players' value, the higher the attendance\n",
    "    v = v + v*playersValue[i]/np.max(playersValue)*0.4\n",
    "    # Hypothesis 3: the higher the victory rate, the higher the attendance\n",
    "    v = v + v*victory[i]**0.5/100\n",
    "    # Correcting for extreme values\n",
    "    if(v < stadiumSize[i]*0.3):\n",
    "        v = stadiumSize[i]*0.2\n",
    "    elif(v > stadiumSize[i]*0.9):\n",
    "        v = stadiumSize[i]*0.9\n",
    "    attendance.append(round(v, -2))\n",
    "#print(attendance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StadiumSize  PlayersValue  PlayersAge  VictoryPercentage  StadiumAttendance\n",
      "0      68900.0     1605000.0       24.15               69.0            62000.0\n",
      "1      51800.0     1376000.0       25.27               58.0            42400.0\n",
      "2      74200.0     1730000.0       28.82               74.0            64000.0\n",
      "3      44400.0     1302000.0       27.05               60.0            19300.0\n",
      "4      41400.0     1168000.0       28.31               52.0            24500.0\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataframe\n",
    "teamsDF = pd.DataFrame(list(zip(stadiumSize, playersValue, playersAge, victory, attendance)))\n",
    "teamsDF.columns =['StadiumSize','PlayersValue','PlayersAge','VictoryPercentage', \"StadiumAttendance\"]\n",
    "print(teamsDF.head())  \n",
    "\n",
    "hf = h2o.H2OFrame(teamsDF, destination_frame = \"teams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "teams = h2o.get_frame(\"teams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling a GBM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test set\n",
    "train, test = teams.split_frame(\n",
    "    ratios = [0.8],\n",
    "    destination_frames = [\"teams_train\", \"teams_test\"],\n",
    "    seed = 123)\n",
    "train = h2o.get_frame(\"teams_train\")\n",
    "test = h2o.get_frame(\"teams_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StadiumSize', 'PlayersValue', 'PlayersAge', 'VictoryPercentage']\n"
     ]
    }
   ],
   "source": [
    "# Defining X and Y variables\n",
    "y = 'StadiumAttendance'\n",
    "ignoreFields = y\n",
    "x = [i for i in train.names if i not in ignoreFields]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Constructing a GBM algorithm (with default hyperparameters and no cross validation)\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "myGBM = H2OGradientBoostingEstimator(model_id = \"baseline_GBM\")\n",
    "myGBM.train(x, y, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GBM baseline model has a MAE of 3248 on the Train set and 4360 on the Test set\n"
     ]
    }
   ],
   "source": [
    "# Model performance\n",
    "print(\"The GBM baseline model has a MAE of %d on the Train set and %d on the Test set\"\n",
    "      % (myGBM.mae(train), myGBM.model_performance(test).mae()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model exhibits better results in the train set than in the test set. Our model overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Completely overfitted model\n",
    "myGBM_overfitted = H2OGradientBoostingEstimator(model_id = \"overfitted_GBM\", ntrees = 1000, max_depth = 10)\n",
    "myGBM_overfitted.train(x, y, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GBM overfitted model has a MAE of 208 on the Train set and 4864 on the Test set\n"
     ]
    }
   ],
   "source": [
    "print(\"The GBM overfitted model has a MAE of %d on the Train set and %d on the Test set\"\n",
    "      % (myGBM_overfitted.mae(train), myGBM_overfitted.model_performance(test).mae()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the train error has significantly falled while the test error has increased. We can conclude that this specification indeed increases the previous overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Constructing a final GBM: using cross validation to reduce overfitting\n",
    "myGBM_cv = H2OGradientBoostingEstimator(model_id = \"crossval_GBM\", nfolds = 20)\n",
    "myGBM_cv.train(x, y, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GBM with cross validation model has a MAE of 3248 on the Train set and 4360 on the Test set\n"
     ]
    }
   ],
   "source": [
    "print(\"The GBM with cross validation model has a MAE of %d on the Train set and %d on the Test set\"\n",
    "      % (myGBM_cv.mae(train), myGBM_cv.model_performance(test).mae()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results exhibited by our CV model seem to be exactly the same as our baseline GBM. While using Cross Val, we train on different samples, so that the results are not supposed to be equal to a default GBM. I suppose I did a mistake somewhere."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
